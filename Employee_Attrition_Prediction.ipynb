{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTplQkOMsKhd"
      },
      "source": [
        "# Employee Attrition Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9wsH4KikGdd"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmh48BKlkIlm"
      },
      "source": [
        "To predict employee attrition using CatBoost and XgBoost "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N0iS4ipU_XM"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8OXq65pVDDS"
      },
      "source": [
        "* explore the employee attrition dataset\n",
        "* apply CatBoost and XgBoost on the dataset\n",
        "* tune the model hyperparameters to improve accuracy\n",
        "* evaluate the model using suitable metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC0AF58YH-cn"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset used for this mini-project is [HR Employee Attrition dataset](https://data.world/aaizemberg/hr-employee-attrition). This dataset is synthetically created by IBM data scientists. There are 35 features and 1470 records. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Dataset"
      ],
      "metadata": {
        "id": "WtkU7_T92gal"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BJzstlcLh4k"
      },
      "source": [
        "### Install CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYeUGMBZeqtL"
      },
      "outputs": [],
      "source": [
        "!pip -qq install catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TmXyc2bRFvM"
      },
      "source": [
        "### Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v50DDzl0CEVk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, f1_score, classification_report, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier, metrics\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use('fivethirtyeight') \n",
        "pd.set_option('display.max_columns', 100)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E7JUtgDYBDL"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhB7KfG7lAi6"
      },
      "source": [
        "**Read the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82VkFRBVSbG7"
      },
      "outputs": [],
      "source": [
        "# read the dataset\n",
        "df = pd.read_csv('/content/wa_fn_usec_hr_employee_attrition_tsv.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/hr_employee_attrition_test.csv')"
      ],
      "metadata": {
        "id": "MfeIQJUhLz5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6QL6HbTZLjw"
      },
      "outputs": [],
      "source": [
        "# Check the shape of dataframe. \n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdlHiFSQ0x7_"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JgkRXxYCEVn"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "- Check for missing values\n",
        "- Check for consistent data type across a feature\n",
        "- Check for outliers or inconsistencies in data columns\n",
        "- Check for correlated features\n",
        "- Do we have a target label imbalance\n",
        "- How our independent variables are distributed relative to our target label\n",
        "- Are there features that have strong linear or monotonic relationships? Making correlation heatmaps makes it easy to identify possible collinearity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNypN2YmlpwG"
      },
      "source": [
        "**Create a `List` of numerical and categorical columns. Display a statistical description of the dataset. Remove missing values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS2ZhwHl1zoM"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNx3U6cD2MQN"
      },
      "outputs": [],
      "source": [
        "categorical = [col for col in df.columns if df[col].dtypes == 'object']\n",
        "numerical = [col for col in df.columns if df[col].dtypes != 'object']\n",
        "\n",
        "categorical.remove('attrition')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[categorical] = df[categorical].astype('category')"
      ],
      "metadata": {
        "id": "-Yvp1xriHlAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "var_thres = VarianceThreshold(threshold=0.2)\n",
        "\n",
        "var_thres.fit(df[numerical])\n",
        "\n",
        "constant_columns = [column for column in df[numerical].columns if column not in df[numerical].columns[var_thres.get_support()]]\n",
        "constant_columns"
      ],
      "metadata": {
        "id": "1nKDQmE-Hvqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in constant_columns:\n",
        "  numerical.remove(i)"
      ],
      "metadata": {
        "id": "M_AKygjfKqw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=constant_columns, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Sqlst4sIHvtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(df.columns)\n",
        "features.remove('attrition')"
      ],
      "metadata": {
        "id": "UBt1BdN5JohJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features_indices = [features.index(cat) for cat in categorical]"
      ],
      "metadata": {
        "id": "YsLtsXYOHcb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features_indices"
      ],
      "metadata": {
        "id": "ax99BWRsHchP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOHYyNvXRwHz"
      },
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5mUbdCMKBP8"
      },
      "source": [
        "### Check for outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYTnAs5UqlVn"
      },
      "source": [
        "**Create a box plot to check for outliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYTxh7gtFqyC"
      },
      "outputs": [],
      "source": [
        "# Check for outliers\n",
        "for num in numerical:\n",
        "  fig, ax = plt.subplots(figsize=(4,4))\n",
        "  sns.boxplot(data=df, x=num, hue='attrition', ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42cBMGHQQOWP"
      },
      "source": [
        "### Handling outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei63U2m7qyGA"
      },
      "source": [
        "**Use lower bound as 25% and upper bound as 75% to handle the outliers**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT3yOFPoH0SH"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQGd7Eoe4tC2"
      },
      "outputs": [],
      "source": [
        "#Function to handle the outliers --\n",
        "def handle_outlier(df, col):\n",
        "  q1 = df[col].describe()['25%']\n",
        "  q3 = df[col].describe()['75%']\n",
        "  iqr = q3 - q1\n",
        "  return np.where(df[col] > q3, q3, np.where(df[col] < q1, q1, df[col]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQS0fxCh4tFp"
      },
      "outputs": [],
      "source": [
        "for num in numerical:\n",
        "  df[num] = handle_outlier(df, num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvrMPhTtJTYP"
      },
      "outputs": [],
      "source": [
        "# Recheck for outliers\n",
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuqzA0g79azH"
      },
      "outputs": [],
      "source": [
        "# Check for outliers\n",
        "for num in numerical:\n",
        "  fig, ax = plt.subplots(figsize=(4,4))\n",
        "  sns.boxplot(data=df, x=num, hue='attrition', ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0zuj4va-kv0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ha6PPo2iCAM"
      },
      "source": [
        "### Target label imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryNwfdldrR0j"
      },
      "source": [
        "**Check if there is an imbalance in target label**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1gsAjfLbi2Z"
      },
      "outputs": [],
      "source": [
        "# Count of unique values in Attrition column\n",
        "df['attrition'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-8bU9moco7l"
      },
      "outputs": [],
      "source": [
        "# Plot barplot to visualize balance/imbalance\n",
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "sns.countplot(df['attrition'], ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REe-FXr4-tX2"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['attrition'])\n",
        "y = df[['attrition']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79pQoaQ3iOG7"
      },
      "source": [
        "###Plot pairplot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hfry_Fwr5nQ"
      },
      "source": [
        "**Visualize the relationships between the predictor variables and the target variable using a pairplot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OO9RJlfrCEVp"
      },
      "outputs": [],
      "source": [
        "# Visualize a pairplot with relevant features\n",
        "sns.pairplot(df[numerical])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVKpOQqPuyew"
      },
      "source": [
        "### Explore Correlation\n",
        "\n",
        "- Plotting the Heatmap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIMCrjr1sNJc"
      },
      "source": [
        "**Visualize the correlation among IBM employee attrition numerical features using a heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC7eIV-P8rbX"
      },
      "outputs": [],
      "source": [
        "# Visualize heatmap\n",
        "fig, ax = plt.subplots(figsize=(15,15))\n",
        "sns.heatmap(df[numerical].corr(), annot=True, ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT9AhvtTQnKV"
      },
      "source": [
        "### Preparing the test feature space\n",
        "* Remove outliers if any\n",
        "* Handle the categorical feature if required\n",
        "* Other processing steps can also be followed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfhan6UWQ8EX"
      },
      "outputs": [],
      "source": [
        "test_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.drop(columns=['id'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "U2brsg8PMLp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.drop(columns=constant_columns, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "S2bidhYoMXgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for num in numerical:\n",
        "  test_df[num] = handle_outlier(test_df, num)"
      ],
      "metadata": {
        "id": "D9le11Q7MShO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "tmfYw8eHC1Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "AoAyaavwIVTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "df['kfold'] = -1\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "for fold, (train_indicies, valid_indicies) in enumerate(skf.split(df.drop(columns=['attrition']), df[['attrition']])):\n",
        "  df.loc[valid_indicies, 'kfold'] = fold"
      ],
      "metadata": {
        "id": "EKVuhD9ANlKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['kfold'].value_counts()"
      ],
      "metadata": {
        "id": "LzbzeDo9DZEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['attrition'] = np.where(df['attrition'] == 'Yes', 1, np.where(df['attrition'] == 'No', 0, df['attrition']))"
      ],
      "metadata": {
        "id": "wZKlxXYePyEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-ZPcVcn9w3U"
      },
      "source": [
        "In the notebook, data processing is done separately for different models.\n",
        "Considering the fact that different models may require data in different format and in turn different processes may be followed to process the data.\n",
        "\n",
        "If the processing steps followed for the models are same, data processing can also be done once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ccGpKffCEVt"
      },
      "source": [
        "## Apply CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d7v3VlYQXGY"
      },
      "source": [
        "### Data Processing for CatBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45hA2ZB9tHGW"
      },
      "source": [
        "**Data processing for CatBoost**\n",
        "* **Copy the dataframe that was created after removing the outliers**\n",
        "* **Handle the categorical features if required**\n",
        "* **Create target column and feature space**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_mmH_ltZPvP"
      },
      "outputs": [],
      "source": [
        "# Copy the data\n",
        "catb_df = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-0M3uWuZs_B"
      },
      "outputs": [],
      "source": [
        "# Target Column\n",
        "y = catb_df[['attrition']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icGflPlLaBre"
      },
      "outputs": [],
      "source": [
        "# Feature Space\n",
        "X = catb_df.drop(columns=['attrition'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features_indices"
      ],
      "metadata": {
        "id": "qZHe1bLWPPbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "7safWdKuPTr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Z0cbeS4BrT"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bphb_wNwupwi"
      },
      "source": [
        "**Define, train the model and display the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIMPGCfMDIZR"
      },
      "outputs": [],
      "source": [
        "# Create CatBoost model\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from sklearn.metrics import f1_score,roc_auc_score\n",
        "\n",
        "prediction = []\n",
        "score = []\n",
        "\n",
        "for fold in range(5):\n",
        "    X_train = catb_df[catb_df.kfold != fold].reset_index(drop=True) \n",
        "    X_val = catb_df[catb_df.kfold == fold].reset_index(drop=True) \n",
        "    X_test = test_df.copy()\n",
        "  \n",
        "    # dependent variables \n",
        "    y_train = X_train['attrition'].astype(int)\n",
        "    y_val = X_val['attrition'].astype(int)\n",
        "\n",
        "    # independent variables\n",
        "    X_train = X_train[features]\n",
        "    X_val = X_val[features]\n",
        "\n",
        "    # catboost modelling \n",
        "    model=CatBoostClassifier(n_estimators=500, max_depth=5, learning_rate=0.01, early_stopping_rounds=5, scale_pos_weight=5)\n",
        "    model.fit(X_train, y_train, cat_features=categorical_features_indices, eval_set=(X_val, y_val), verbose=False)\n",
        "\n",
        "    preds_valid = model.predict(X_val)\n",
        "\n",
        "    #Training model apply the test data and predict the output\n",
        "    test_predict = model.predict(X_test)\n",
        "    prediction.append(test_predict)\n",
        "    f1= f1_score(y_val,preds_valid, average='weighted')\n",
        "\n",
        "    #Score \n",
        "    score.append(f1)\n",
        "    print(f\"fold:{fold},f1 score:{f1}\")\n",
        "\n",
        "print(np.mean(score),np.std(score))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "S8kP7NBtQTjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna \n",
        "\n",
        "def hyp_optimizer(trial):\n",
        "    fold = 0\n",
        "    # hyperparameters for CatBoost\n",
        "    param = {}\n",
        "    param['learning_rate'] = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n",
        "    param['depth'] = trial.suggest_int('depth', 1, 11)\n",
        "    param['scale_pos_weight'] = trial.suggest_int('scale_pos_weight', 1, 10)\n",
        "    param['l2_leaf_reg'] = trial.suggest_float('l2_leaf_reg', 0.0001, 1.0, log = True)\n",
        "    param['min_child_samples'] = trial.suggest_categorical('min_child_samples', [1, 4, 8, 16, 32])\n",
        "    param['subsample'] = trial.suggest_float('subsample', 0.1, 0.8)\n",
        "    param['n_estimators'] = trial.suggest_int('n_estimators', 500, 8000)     \n",
        "    param['early_stopping_rounds'] = trial.suggest_int('early_stopping_rounds', 5, 100)                                  \n",
        "    param['grow_policy'] = 'Depthwise'\n",
        "    param['use_best_model'] = True\n",
        "    param['eval_metric'] = 'F1'\n",
        "    param['od_type'] = 'Iter'\n",
        "    param['od_wait'] = 50\n",
        "    param['random_state'] = 42\n",
        "    param['logging_level'] = 'Silent'\n",
        "\n",
        "\n",
        "    X_train = catb_df[catb_df.kfold != fold].reset_index(drop=True)\n",
        "    X_val = catb_df[catb_df.kfold == fold].reset_index(drop=True)\n",
        "    # X_test = test_df.copy()\n",
        "\n",
        "    # dependent variables \n",
        "    y_train = X_train['attrition'].astype(int)\n",
        "    y_val = X_val['attrition'].astype(int)\n",
        "\n",
        "    # independent variables\n",
        "    X_train = X_train[features]\n",
        "    X_val = X_val[features]\n",
        "\n",
        "    # catboost modelling \n",
        "    model=CatBoostClassifier(**param)\n",
        "    model.fit(X_train, y_train,cat_features=categorical_features_indices,eval_set=(X_val, y_val),plot=True)\n",
        "\n",
        "    preds_valid = model.predict(X_val)\n",
        "\n",
        "    #Training model apply the test data and predict the output\n",
        "    # test_predict = model.predict(X_test)\n",
        "    # prediction.append(test_predict)\n",
        "    f1= f1_score(y_val,preds_valid, average='weighted')\n",
        "\n",
        "    #Score \n",
        "    # score.append(roc1)\n",
        "    # print(f\"fold:{fold},roc:{roc1}\")\n",
        "\n",
        "    return f1"
      ],
      "metadata": {
        "id": "v1cXqKqTQSFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(hyp_optimizer, n_trials=100)"
      ],
      "metadata": {
        "id": "vA4S3_ACTGhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(study.best_params)\n",
        "print(study.best_trial) "
      ],
      "metadata": {
        "id": "PIDfrOfLXEqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CatBoost model\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from sklearn.metrics import f1_score,roc_auc_score\n",
        "\n",
        "prediction = []\n",
        "score = []\n",
        "\n",
        "for fold in range (5):\n",
        "    X_train = catb_df[catb_df.kfold != fold].reset_index(drop=True)\n",
        "    X_val = catb_df[catb_df.kfold == fold].reset_index(drop=True)\n",
        "    X_test = test_df.copy()\n",
        "\n",
        "    param = {}\n",
        "    param['learning_rate'] = 0.07696560775064637\n",
        "    param['depth'] = 3\n",
        "    param['scale_pos_weight'] = 3\n",
        "    param['l2_leaf_reg'] = 0.004017265423496804\n",
        "    param['min_child_samples'] = 8\n",
        "    param['subsample'] = 0.3799643651983675\n",
        "    param['n_estimators'] = 3731                                    \n",
        "    param['grow_policy'] = 'Depthwise'\n",
        "    param['use_best_model'] = True\n",
        "    param['eval_metric'] = 'F1'\n",
        "    param['od_type'] = 'Iter'\n",
        "    param['od_wait'] = 50\n",
        "    param['random_state'] = 42\n",
        "    param['logging_level'] = 'Silent'\n",
        "  \n",
        "    # dependent variables \n",
        "    y_train = X_train['attrition'].astype(int)\n",
        "    y_val = X_val['attrition'].astype(int)\n",
        "\n",
        "    # independent variables\n",
        "    X_train = X_train[features]\n",
        "    X_val = X_val[features]\n",
        "\n",
        "    # catboost modelling \n",
        "    model=CatBoostClassifier(**param)\n",
        "    model.fit(X_train, y_train, cat_features=categorical_features_indices, eval_set=(X_val, y_val), verbose=False)\n",
        "\n",
        "    preds_valid = model.predict(X_val)\n",
        "\n",
        "    #Training model apply the test data and predict the output\n",
        "    test_predict = model.predict(X_test)\n",
        "    prediction.append(test_predict)\n",
        "    f1= f1_score(y_val,preds_valid, average='weighted')\n",
        "\n",
        "    #Score \n",
        "    score.append(f1)\n",
        "    print(f\"fold:{fold},f1 score:{f1}\")\n",
        "\n",
        "print(np.mean(score),np.std(score))"
      ],
      "metadata": {
        "id": "Q5dFo-sdboWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "id": "n8mo_HrlY_hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predict = stats.mode(np.column_stack(prediction),axis=1, keepdims=True)[0]"
      ],
      "metadata": {
        "id": "aakCacB4cr3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.index += 1"
      ],
      "metadata": {
        "id": "Of6GDNardPlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.index.name = 'id'\n",
        "test_df['label'] = final_predict"
      ],
      "metadata": {
        "id": "4l5eFb3Ucla0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "id": "j99iGeiDZRXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[['label']].to_csv('final_submission_df.csv')"
      ],
      "metadata": {
        "id": "WWRkZFQvdcHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hk4Kw5QGXCU"
      },
      "source": [
        "## Apply XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KbfDzqudx5H"
      },
      "source": [
        "### Data Processing for XGBoost\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk6NedArvxbn"
      },
      "source": [
        "**Data Processing for XGBoost**\n",
        "* **Copy the dataframe after the outliers were removed.**\n",
        "* **Handle the categorical features if required**\n",
        "* **Create target column and feature space**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT2RVw4JTAGp"
      },
      "outputs": [],
      "source": [
        "# Copy dataframe\n",
        "xgb_df = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_test_df = test_df.copy()"
      ],
      "metadata": {
        "id": "R62aLVivYGry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX1wnlPFWViw"
      },
      "outputs": [],
      "source": [
        "# Handling categorical features\n",
        "categorical_df = pd.get_dummies(xgb_df[categorical])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-K7vfixWup8"
      },
      "outputs": [],
      "source": [
        "# Concat the dummy variables to actual dataframe and remove initial categorical columns\n",
        "xgb_df.drop(columns=categorical, inplace=True)\n",
        "\n",
        "xgb_df = pd.concat([xgb_df, categorical_df], axis=1)\n",
        "\n",
        "xgb_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA-WIpLAX3KH"
      },
      "outputs": [],
      "source": [
        "# Feature Space\n",
        "X = xgb_df.drop(columns=['attrition'])\n",
        "\n",
        "# Targer label\n",
        "y = xgb_df[['attrition']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_features = list(xgb_df.columns)\n",
        "new_features.remove('attrition')\n",
        "new_features.remove('kfold')"
      ],
      "metadata": {
        "id": "vIIY-PJ-WocN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_categorical_df = pd.get_dummies(test_df[categorical])\n",
        "\n",
        "new_test_df.drop(columns=categorical, inplace=True)\n",
        "\n",
        "new_test_df = pd.concat([new_test_df, test_categorical_df], axis=1)\n",
        "\n",
        "new_test_df.columns"
      ],
      "metadata": {
        "id": "ZWMPuiO4Xli7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccLyB9J04hDF"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPinBk5NxRpt"
      },
      "source": [
        "**Define, train the model and display the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxtvfYpzVxTc"
      },
      "outputs": [],
      "source": [
        "# Create XGBoost classifier model\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "prediction = []\n",
        "score = []\n",
        "\n",
        "for fold in range (5):\n",
        "    X_train = xgb_df[xgb_df.kfold != fold].reset_index(drop=True)\n",
        "    X_val = xgb_df[xgb_df.kfold == fold].reset_index(drop=True)\n",
        "    X_test = new_test_df.copy()\n",
        "  \n",
        "    # dependent variables \n",
        "    y_train = X_train['attrition'].astype(int)\n",
        "    y_val = X_val['attrition'].astype(int)\n",
        "\n",
        "    # independent variables\n",
        "    X_train = X_train[new_features]\n",
        "    X_val = X_val[new_features]\n",
        "\n",
        "    # xgboost modelling \n",
        "    model = XGBClassifier()\n",
        "    model.fit(X_train,y_train,early_stopping_rounds=100,eval_set=[(X_val,y_val)],verbose=False)\n",
        "\n",
        "    preds_valid = model.predict(X_val)\n",
        "\n",
        "    #Training model apply the test data and predict the output\n",
        "    test_predict = model.predict(X_test)\n",
        "    prediction.append(test_predict)\n",
        "    f1= f1_score(y_val,preds_valid, average='weighted')\n",
        "    roc = roc_auc_score(y_val, preds_valid)\n",
        "    acc = accuracy_score(y_val, preds_valid)\n",
        "\n",
        "    #Score \n",
        "    score.append(f1)\n",
        "    print(f\"fold:{fold},f1 score:{f1}\")\n",
        "    print(f\"fold:{fold},roc score:{roc}\")\n",
        "    print(f\"fold:{fold},accuracy score:{acc}\")\n",
        "    print('-'*15)\n",
        "\n",
        "\n",
        "print(np.mean(score),np.std(score))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IPpfREsArdJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "Ny9MJcMphD8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna"
      ],
      "metadata": {
        "id": "xp7LioLchIsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning - XGBoost "
      ],
      "metadata": {
        "id": "Rj78LJG_iDbF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrN85N3X_Sar"
      },
      "outputs": [],
      "source": [
        "def hyp_optimizer_xgb(trial):\n",
        "    fold = 2\n",
        "    # hyperparameters for XGBoost\n",
        "    param = {}\n",
        "\n",
        "    param['learning_rate'] = trial.suggest_float(\"learning_rate\", 0.001, 1, log=True)\n",
        "    param['n_estimators'] = trial.suggest_int('n_estimators', 100, 8000)\n",
        "    param['scale_pos_weight'] = trial.suggest_int('scale_pos_weight', 1, 10)\n",
        "    param['reg_lambda'] = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
        "    param['reg_alpha'] = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
        "    param['subsample'] = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
        "    param['colsample_bytree'] = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
        "    param['max_depth'] = trial.suggest_int(\"max_depth\", 1,20)\n",
        "    param['eval_metric'] = 'auc'\n",
        "\n",
        "    X_train = xgb_df[xgb_df.kfold != fold].reset_index(drop=True)\n",
        "    X_val = xgb_df[xgb_df.kfold == fold].reset_index(drop=True)\n",
        "    # X_test = test_df.copy()\n",
        "\n",
        "    # dependent variables \n",
        "    y_train = X_train['attrition'].astype(int)\n",
        "    y_val = X_val['attrition'].astype(int)\n",
        "\n",
        "    # independent variables\n",
        "    X_train = X_train[new_features]\n",
        "    X_val = X_val[new_features]\n",
        "\n",
        "    # XGBRegressor moddelling \n",
        "    model = XGBClassifier(**param)\n",
        "\n",
        "    # pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-auc\")\n",
        "\n",
        "    model.fit(X_train,y_train,early_stopping_rounds=100,eval_set=[(X_val,y_val)], verbose=False)\n",
        "\n",
        "    preds_valid = model.predict(X_val)\n",
        "\n",
        "    #Training model apply the test data and predict the output\n",
        "    # test_predict = model.predict(X_test)\n",
        "    # prediction.append(test_predict)\n",
        "    f1= f1_score(y_val,preds_valid, average='weighted')\n",
        "\n",
        "    #Score \n",
        "    # score.append(roc1)\n",
        "    # print(f\"fold:{fold},roc:{roc1}\")\n",
        "\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(hyp_optimizer_xgb, n_trials=100)"
      ],
      "metadata": {
        "id": "II2-M575bIki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(study.best_params)\n",
        "print(study.best_trial) "
      ],
      "metadata": {
        "id": "_1-ZebfihZSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create XGBoost classifier model with optimal hyperparameters\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "prediction = []\n",
        "score = []\n",
        "\n",
        "for fold in range(5):\n",
        "    X_train = xgb_df[xgb_df.kfold != fold].reset_index(drop=True)\n",
        "    X_val = xgb_df[xgb_df.kfold == fold].reset_index(drop=True)\n",
        "    \n",
        "    X_test = new_test_df.copy()\n",
        "\n",
        "    param = {}\n",
        "    param['learning_rate'] = study.best_params['learning_rate']\n",
        "    param['n_estimators'] = study.best_params['n_estimators']\n",
        "    param['scale_pos_weight'] = study.best_params['scale_pos_weight']\n",
        "    param['reg_lambda'] = study.best_params['reg_lambda']\n",
        "    param['reg_alpha'] = study.best_params['reg_alpha']\n",
        "    param['subsample'] = study.best_params['subsample']\n",
        "    param['colsample_bytree'] = study.best_params['colsample_bytree']\n",
        "    param['max_depth'] = study.best_params['max_depth']\n",
        "    param['eval_metric'] = 'auc'\n",
        "\n",
        "  \n",
        "    # dependent variables \n",
        "    y_train = X_train['attrition'].astype(int)\n",
        "    y_val = X_val['attrition'].astype(int)\n",
        "\n",
        "    # independent variables\n",
        "    X_train = X_train[new_features]\n",
        "    X_val = X_val[new_features]\n",
        "\n",
        "    # xgboost modelling \n",
        "    model = XGBClassifier(**param)\n",
        "    model.fit(X_train,y_train,early_stopping_rounds=100,eval_set=[(X_val,y_val)],verbose=False)\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    # preds_proba = model.predict_proba(X_val)[:, 1]\n",
        "  \n",
        "    # fpr1, tpr1, thresh1 = roc_curve(y_val, preds_proba)\n",
        "\n",
        "    # gmeans = np.sqrt(tpr1 * (1-fpr1))\n",
        "    # ix = np.argmax(gmeans)\n",
        "\n",
        "    # y_pred = np.where(preds_proba >=0.45, 1, 0)\n",
        "    # preds_valid = model.predict(X_val)\n",
        "\n",
        "    #Training model apply the test data and predict the output\n",
        "    test_predict = model.predict(X_test)\n",
        "    # test_predict_proba = model.predict_proba(X_test)\n",
        "    # test_predict = np.where(test_predict_proba >=0.45, 1, 0)\n",
        "    prediction.append(test_predict)\n",
        "\n",
        "    f1= f1_score(y_val,y_pred, average='weighted')\n",
        "    roc = roc_auc_score(y_val, y_pred)\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "\n",
        "    #Score \n",
        "    score.append(f1)\n",
        "    print(f\"fold:{fold},f1 score:{f1}\")\n",
        "    print(f\"fold:{fold},roc score:{roc}\")\n",
        "    print(f\"fold:{fold},accuracy score:{acc}\")\n",
        "    print('-'*15)\n",
        "\n",
        "print(np.mean(score),np.std(score))"
      ],
      "metadata": {
        "id": "pubV7vXGhjwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA5ZK31mPox1"
      },
      "source": [
        "### Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_predict_mean = np.mean(np.column_stack(prediction),axis=1)"
      ],
      "metadata": {
        "id": "dhCKtgSZi9PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predict_mean"
      ],
      "metadata": {
        "id": "cUmbjEjklweg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predict_values = np.where(final_predict_mean>0.4, 1, 0)"
      ],
      "metadata": {
        "id": "WJ6R3ARSjFHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQXg9FhcmwIw"
      },
      "outputs": [],
      "source": [
        "final_predict = stats.mode(np.column_stack(prediction),axis=1, keepdims=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.index -= 1"
      ],
      "metadata": {
        "id": "R9abjvjNrQog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.index.name = 'id'"
      ],
      "metadata": {
        "id": "GzWrMbjyszf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['label'] = final_predict_values\n",
        "test_df[['label']].to_csv('final_submission_df10.csv')"
      ],
      "metadata": {
        "id": "lnA9UgcKic0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Iki__IJCEVs"
      },
      "source": [
        "## Apply LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGVwrT59tEx_"
      },
      "source": [
        "### Feature Engineering for LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYq9Z02Bs4-x"
      },
      "outputs": [],
      "source": [
        "## Following the same procedure as followed in XGBoost\n",
        "\n",
        "# Copy the dataframe\n",
        "lgbm_df = df.copy()  \n",
        "\n",
        "# Handling categorical features\n",
        "categorical_df = pd.get_dummies(lgbm_df[categorical])\n",
        "\n",
        "# Concat the dummy variables to actual dataframe and remove initial categorical columns\n",
        "lgbm_df.drop(columns=categorical, inplace=True)\n",
        "lgbm_df = pd.concat([lgbm_df, categorical_df], axis=1)\n",
        " \n",
        "# Feature Space\n",
        "X = lgbm_df.drop(columns=['attrition'])\n",
        "\n",
        "# Targer label\n",
        "y = lgbm_df[['attrition']]   \n",
        "\n",
        "new_features = list(lgbm_df.columns)\n",
        "new_features.remove('attrition')\n",
        "new_features.remove('kfold')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNxN3-gU4ZWn"
      },
      "source": [
        "### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LightGBM classifier model\n",
        "prediction = []\n",
        "score = []\n",
        "\n",
        "for fold in range (5):\n",
        "  X_train = lgbm_df[lgbm_df.kfold != fold].reset_index(drop=True)\n",
        "  X_val = lgbm_df[lgbm_df.kfold == fold].reset_index(drop=True)\n",
        "  X_test = new_test_df.copy()\n",
        "\n",
        "  # dependent variables \n",
        "  y_train = X_train['attrition'].astype(int)\n",
        "  y_val = X_val['attrition'].astype(int)\n",
        "\n",
        "  # independent variables\n",
        "  X_train = X_train[new_features]\n",
        "  X_val = X_val[new_features]\n",
        "\n",
        "  # lgbm modelling\n",
        "  model = LGBMClassifier(learning_rate = 0.1)\n",
        "  model.fit(X_train, y_train, early_stopping_rounds=100, eval_set=[(X_val,y_val)], verbose=False)\n",
        "\n",
        "  preds_valid = model.predict(X_val)\n",
        "\n",
        "  #Training model apply the test data and predict the output\n",
        "  test_predict = model.predict(X_test)\n",
        "  prediction.append(test_predict)\n",
        "  f1= f1_score(y_val,preds_valid, average='weighted')\n",
        "\n",
        "  #Score \n",
        "  score.append(f1)\n",
        "  print(f\"fold:{fold},f1 score:{f1}\")\n",
        "\n",
        "print(np.mean(score),np.std(score))"
      ],
      "metadata": {
        "id": "d_47bFz_v_0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_df"
      ],
      "metadata": {
        "id": "GophhNAgBQbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fWl23dHXHAP"
      },
      "outputs": [],
      "source": [
        "# Create LightGBM classifier model\n",
        "import optuna\n",
        "\n",
        "def hyp_optimizer_lgbm(trial):\n",
        "  prediction = []\n",
        "  score = []\n",
        "\n",
        "  fold = 0\n",
        "  X_train = lgbm_df[lgbm_df.kfold != fold].reset_index(drop=True)\n",
        "  X_val = lgbm_df[lgbm_df.kfold == fold].reset_index(drop=True)\n",
        "  X_test = new_test_df.copy()\n",
        "\n",
        "  param = {}\n",
        "\n",
        "  param['learning_rate'] = trial.suggest_float(\"learning_rate\", 0.001, 1, log=True)\n",
        "  param['n_estimators'] = trial.suggest_int('n_estimators', 100, 8000)\n",
        "  param['scale_pos_weight'] = trial.suggest_int('scale_pos_weight', 1, 10)\n",
        "  param['reg_lambda'] = trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0)\n",
        "  param['reg_alpha'] = trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0)\n",
        "  param['subsample'] = trial.suggest_float(\"subsample\", 0.1, 1.0)\n",
        "  param['colsample_bytree'] = trial.suggest_float(\"colsample_bytree\", 0.1, 1.0)\n",
        "  param['max_depth'] = trial.suggest_int(\"max_depth\", 1,20)\n",
        "  # param['num_leaves'] = trial.suggest_int('num_leaves', 1, 1000)\n",
        "  # param['min_child_samples'] = trial.suggest_int('min_child_samples', 1, 300)\n",
        "  # param['cat_smooth'] = trial.suggest_int('min_data_per_groups', 1, 100)\n",
        "\n",
        "\n",
        "  # dependent variables \n",
        "  y_train = X_train['attrition'].astype(int)\n",
        "  y_val = X_val['attrition'].astype(int)\n",
        "\n",
        "  # independent variables\n",
        "  X_train = X_train[new_features]\n",
        "  X_val = X_val[new_features]\n",
        "\n",
        "  # xgboost modelling \n",
        "  model = LGBMClassifier(**param)\n",
        "  model.fit(X_train, y_train, early_stopping_rounds=100, eval_set=[(X_val,y_val)], verbose=False)\n",
        "\n",
        "  preds_valid = model.predict(X_val)\n",
        "\n",
        "  #Training model apply the test data and predict the output\n",
        "  # test_predict = model.predict(X_test)\n",
        "  # prediction.append(test_predict)\n",
        "  f1 = f1_score(y_val,preds_valid, average='weighted')\n",
        "\n",
        "  #Score \n",
        "  # score.append(roc1)\n",
        "  # print(f\"fold:{fold},roc:{roc1}\")\n",
        "\n",
        "  return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FktD02ntN1T"
      },
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(hyp_optimizer_lgbm, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(study.best_params)\n",
        "print(study.best_trial) "
      ],
      "metadata": {
        "id": "mgQfW9VE10cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LightGBM classifier model\n",
        "prediction = []\n",
        "score = []\n",
        "\n",
        "for fold in range (5):\n",
        "  X_train = lgbm_df[lgbm_df.kfold != fold].reset_index(drop=True)\n",
        "  X_val = lgbm_df[lgbm_df.kfold == fold].reset_index(drop=True)\n",
        "  X_test = new_test_df.copy()\n",
        "\n",
        "  # dependent variables \n",
        "  y_train = X_train['attrition'].astype(int)\n",
        "  y_val = X_val['attrition'].astype(int)\n",
        "\n",
        "  # independent variables\n",
        "  X_train = X_train[new_features]\n",
        "  X_val = X_val[new_features]\n",
        "\n",
        "  param = {}\n",
        "\n",
        "  param['learning_rate'] = 0.08670857337862124\n",
        "  param['n_estimators'] = 2102\n",
        "  param['scale_pos_weight'] = 4\n",
        "  param['reg_lambda'] = 0.000978358022453289\n",
        "  param['reg_alpha'] = 1.052363669709034e-08\n",
        "  param['subsample'] = 0.9158804914976686\n",
        "  param['colsample_bytree'] = 0.9135279801031584\n",
        "  param['max_depth'] = 20\n",
        "\n",
        "  # lgbm modelling\n",
        "  model = LGBMClassifier(**param)\n",
        "  model.fit(X_train, y_train, early_stopping_rounds=100, eval_set=[(X_val,y_val)], verbose=False)\n",
        "\n",
        "  preds_valid = model.predict(X_val)\n",
        "\n",
        "  #Training model apply the test data and predict the output\n",
        "  test_predict = model.predict(X_test)\n",
        "  prediction.append(test_predict)\n",
        "  f1= f1_score(y_val,preds_valid, average='weighted')\n",
        "  roc = roc_auc_score(y_val,preds_valid)\n",
        "  acc = accuracy_score(y_val,preds_valid)\n",
        "\n",
        "  #Score \n",
        "  score.append(f1)\n",
        "  print(f\"fold:{fold},f1 score:{f1}\")\n",
        "  print(f\"fold:{fold},roc:{roc}\")\n",
        "  print(f\"fold:{fold},accuracy:{acc}\")\n",
        "  print('-'*10)\n",
        "\n",
        "print(np.mean(score),np.std(score))"
      ],
      "metadata": {
        "id": "xfaqvIK11_4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upM6hxP_SbPw"
      },
      "source": [
        "### Model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmM2WvTGSd_l"
      },
      "outputs": [],
      "source": [
        "final_predict = stats.mode(np.column_stack(prediction),axis=1, keepdims=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['label'] = final_predict\n",
        "test_df[['label']].to_csv('final_submission_df3.csv')"
      ],
      "metadata": {
        "id": "6KsXaQd14TvO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}